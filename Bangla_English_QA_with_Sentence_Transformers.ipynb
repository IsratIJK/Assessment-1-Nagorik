{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKJ9W_0aEoZC",
        "outputId": "2c767c0e-543f-4d7f-f25f-3c14a1e2b4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.8.30)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.12.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Installing necessary libraries\n",
        "!pip install sentence-transformers pandas googletrans==4.0.0-rc1 datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util  # For semantic similarity and retrieval\n",
        "from googletrans import Translator  # For translating between English and Bangla\n",
        "from transformers import pipeline  # For performing question-answering tasks"
      ],
      "metadata": {
        "id": "LJqsjKimIjKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing translator, QA pipelines, and SentenceTransformer model\n",
        "translator = Translator()  # Translator for handling language translation tasks\n",
        "english_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")  # English QA model\n",
        "multilingual_pipeline = pipeline(\"question-answering\", model=\"xlm-roberta-base\")  # Multilingual QA model\n",
        "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Sentence embedding model for context retrieval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEgXQW7pIkub",
        "outputId": "75902fb4-e153-4109-c937-37b2b684e004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### PART 1: Bigger Dataset Creation ###\n",
        "\n",
        "# Creating a larger English dataset for testing\n",
        "def create_large_combined_dataset():\n",
        "    # Defining a list of dictionaries with context and questions\n",
        "    data = [\n",
        "        {\n",
        "            \"context\": \"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods from carbon dioxide and water.\",\n",
        "            \"question\": \"What is photosynthesis?\"\n",
        "        },\n",
        "        {\n",
        "            \"context\": \"The Eiffel Tower is one of the most iconic structures in the world, located in Paris, France.\",\n",
        "            \"question\": \"Where is the Eiffel Tower located?\"\n",
        "        },\n",
        "        {\n",
        "            \"context\": \"Blockchain is a decentralized digital ledger used for recording transactions securely and transparently.\",\n",
        "            \"question\": \"What is blockchain?\"\n",
        "        },\n",
        "        {\n",
        "            \"context\": \"Leonardo da Vinci was a polymath of the Renaissance period known for his works such as the Mona Lisa and The Last Supper.\",\n",
        "            \"question\": \"Who was Leonardo da Vinci?\"\n",
        "        },\n",
        "        {\n",
        "            \"context\": \"Climate change refers to long-term shifts in temperatures and weather patterns, primarily due to human activities.\",\n",
        "            \"question\": \"What is climate change?\"\n",
        "        },\n",
        "        {\n",
        "            \"context\": \"The Amazon rainforest is the largest tropical rainforest in the world, home to diverse flora and fauna.\",\n",
        "            \"question\": \"What is the Amazon rainforest known for?\"\n",
        "        },\n",
        "        {\n",
        "            \"context\": \"Python is a versatile programming language that supports multiple programming paradigms.\",\n",
        "            \"question\": \"What type of programming language is Python?\"\n",
        "        },\n",
        "        {\n",
        "            \"context\": \"The Moon orbits the Earth and is its only natural satellite, influencing tides and nighttime illumination.\",\n",
        "            \"question\": \"What is the Moon's relationship with Earth?\"\n",
        "        }\n",
        "    ]\n",
        "    # Creating a DataFrame and saving it to a CSV file\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(\"large_combined_dataset.csv\", index=False)\n",
        "    print(\"Large English dataset created and saved to large_combined_dataset.csv\")"
      ],
      "metadata": {
        "id": "BbgweWhJIp6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the function to create the dataset\n",
        "create_large_combined_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCo6h7r0I0h5",
        "outputId": "922ddbac-41d3-4d8f-d9b7-95f242f23f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large English dataset created and saved to large_combined_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### PART 2: Translating Dataset to Bangla ###\n",
        "\n",
        "# Translating the English dataset to Bangla\n",
        "def translate_to_bangla(input_csv, output_csv):\n",
        "    # Reading the English dataset\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Translating context and questions to Bangla\n",
        "    df['context_bn'] = df['context'].apply(lambda x: translator.translate(x, src='en', dest='bn').text)\n",
        "    df['question_bn'] = df['question'].apply(lambda x: translator.translate(x, src='en', dest='bn').text)\n",
        "\n",
        "    # Debugging: Printing the first few rows to ensure correct translation\n",
        "    print(df.head())\n",
        "\n",
        "    # Saving the translated dataset to a CSV file\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"Translated Bangla dataset saved to {output_csv}\")"
      ],
      "metadata": {
        "id": "OJtM6PWOI6fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the function to translate the dataset\n",
        "translate_to_bangla(\"large_combined_dataset.csv\", \"translated_large_combined_dataset.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvzcwbxcJDr5",
        "outputId": "0b4ec1d9-dca3-46e3-9707-c907851d25ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             context  \\\n",
            "0  Photosynthesis is the process by which green p...   \n",
            "1  The Eiffel Tower is one of the most iconic str...   \n",
            "2  Blockchain is a decentralized digital ledger u...   \n",
            "3  Leonardo da Vinci was a polymath of the Renais...   \n",
            "4  Climate change refers to long-term shifts in t...   \n",
            "\n",
            "                             question  \\\n",
            "0             What is photosynthesis?   \n",
            "1  Where is the Eiffel Tower located?   \n",
            "2                 What is blockchain?   \n",
            "3          Who was Leonardo da Vinci?   \n",
            "4             What is climate change?   \n",
            "\n",
            "                                          context_bn  \\\n",
            "0  সালোকসংশ্লেষণ হ'ল প্রক্রিয়া যার মাধ্যমে সবুজ ...   \n",
            "1  আইফেল টাওয়ারটি ফ্রান্সের প্যারিসে অবস্থিত বিশ...   \n",
            "2  ব্লকচেইন হ'ল একটি বিকেন্দ্রীভূত ডিজিটাল লেজার ...   \n",
            "3  লিওনার্দো দা ভিঞ্চি ছিলেন মোনা লিসা এবং দ্য লা...   \n",
            "4  জলবায়ু পরিবর্তন মূলত মানুষের ক্রিয়াকলাপের কা...   \n",
            "\n",
            "                       question_bn  \n",
            "0                সালোকসংশ্লেষণ কী?  \n",
            "1  আইফেল টাওয়ারটি কোথায় অবস্থিত?  \n",
            "2                     ব্লকচেইন কী?  \n",
            "3    লিওনার্দো দা ভিঞ্চি কে ছিলেন?  \n",
            "4             জলবায়ু পরিবর্তন কি?  \n",
            "Translated Bangla dataset saved to translated_large_combined_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### PART 3: Simplified Retrieval (RAG) ###\n",
        "\n",
        "# Retrieving the most relevant context using semantic similarity\n",
        "def retrieve_context(question, documents):\n",
        "    \"\"\"\n",
        "    Retrieve the most relevant context from documents using sentence embeddings.\n",
        "    :param question: User's question\n",
        "    :param documents: List of documents\n",
        "    :return: Most relevant context\n",
        "    \"\"\"\n",
        "    # Encoding the question and documents as sentence embeddings\n",
        "    question_embedding = sentence_model.encode(question, convert_to_tensor=True)\n",
        "    document_embeddings = sentence_model.encode(documents, convert_to_tensor=True)\n",
        "\n",
        "    # Calculating similarity scores\n",
        "    scores = util.pytorch_cos_sim(question_embedding, document_embeddings)\n",
        "    best_doc_idx = scores.argmax().item()  # Getting the index of the best matching document\n",
        "\n",
        "    return documents[best_doc_idx]"
      ],
      "metadata": {
        "id": "Sy7bvV46JIY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### PART 4: Direct Preference Optimization (DPO) ###\n",
        "\n",
        "# Ranking answers based on a simple heuristic\n",
        "def rank_answers_with_dpo(answers):\n",
        "    \"\"\"\n",
        "    Rank answers using a simple heuristic (like length of the answer).\n",
        "    :param answers: List of answers\n",
        "    :return: Best answer\n",
        "    \"\"\"\n",
        "    # Selecting the longest answer as the best (simple heuristic)\n",
        "    best_answer = max(answers, key=len)\n",
        "    return best_answer"
      ],
      "metadata": {
        "id": "CEiPzfvNJNNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### PART 5: Processing and Printing English and Bangla Answers Separately ###\n",
        "\n",
        "# Processing the dataset and printing English and Bangla answers separately\n",
        "def process_and_print_answers(input_csv):\n",
        "    # Reading the dataset\n",
        "    df = pd.read_csv(input_csv)\n",
        "\n",
        "    # Initializing lists to store answers\n",
        "    answers_en = []  # English answers\n",
        "    answers_bn = []  # Bangla answers\n",
        "\n",
        "    # Printing English answers\n",
        "    print(\"English QA Results\")\n",
        "    print(\"{:<5} {:<80} {:<50}\".format(\"No.\", \"English Context\", \"English Answer\"))\n",
        "    print(\"=\" * 140)\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        # Retrieving English context\n",
        "        retrieved_context_en = retrieve_context(row['question'], [row['context']])\n",
        "\n",
        "        # Processing English context and question\n",
        "        try:\n",
        "            result_en = english_pipeline({'context': retrieved_context_en, 'question': row['question']})\n",
        "            answers_en.append(result_en['answer'])\n",
        "        except Exception as e:\n",
        "            answers_en.append(f\"Error: {e}\")\n",
        "\n",
        "        # Printing the results for English QA\n",
        "        print(\"{:<5} {:<80} {:<50}\".format(idx + 1, row['context'], answers_en[-1]))\n",
        "\n",
        "    print(\"\\n\\nBangla QA Results\")\n",
        "    print(\"{:<5} {:<80} {:<50}\".format(\"No.\", \"Bangla Context\", \"Bangla Answer\"))\n",
        "    print(\"=\" * 140)\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        # Retrieving Bangla context\n",
        "        retrieved_context_bn = retrieve_context(row['question'], [row['context_bn']])\n",
        "\n",
        "        # Processing Bangla context and question\n",
        "        try:\n",
        "            result_bn = multilingual_pipeline({'context': retrieved_context_bn, 'question': row['question_bn']})\n",
        "            answers_bn.append(result_bn['answer'])\n",
        "        except Exception as e:\n",
        "            answers_bn.append(f\"Error: {e}\")\n",
        "\n",
        "        # Printing the results for Bangla QA\n",
        "        print(\"{:<5} {:<80} {:<50}\".format(idx + 1, row['context_bn'], answers_bn[-1]))"
      ],
      "metadata": {
        "id": "5WSCIOJRJeXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the function to process and print QA results\n",
        "process_and_print_answers(\"translated_large_combined_dataset.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiLfQYaIJhvB",
        "outputId": "6a6e6953-0b4e-4375-b26e-9978ab3ea2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English QA Results\n",
            "No.   English Context                                                                  English Answer                                    \n",
            "============================================================================================================================================\n",
            "1     Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods from carbon dioxide and water. the process by which green plants and some other organisms use sunlight\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/question_answering.py:391: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2     The Eiffel Tower is one of the most iconic structures in the world, located in Paris, France. Paris, France                                     \n",
            "3     Blockchain is a decentralized digital ledger used for recording transactions securely and transparently. a decentralized digital ledger                    \n",
            "4     Leonardo da Vinci was a polymath of the Renaissance period known for his works such as the Mona Lisa and The Last Supper. a polymath                                        \n",
            "5     Climate change refers to long-term shifts in temperatures and weather patterns, primarily due to human activities. long-term shifts in temperatures and weather patterns\n",
            "6     The Amazon rainforest is the largest tropical rainforest in the world, home to diverse flora and fauna. diverse flora and fauna                           \n",
            "7     Python is a versatile programming language that supports multiple programming paradigms. versatile                                         \n",
            "8     The Moon orbits the Earth and is its only natural satellite, influencing tides and nighttime illumination. influencing tides and nighttime illumination      \n",
            "\n",
            "\n",
            "Bangla QA Results\n",
            "No.   Bangla Context                                                                   Bangla Answer                                     \n",
            "============================================================================================================================================\n",
            "1     সালোকসংশ্লেষণ হ'ল প্রক্রিয়া যার মাধ্যমে সবুজ উদ্ভিদ এবং কিছু অন্যান্য জীব কার্বন ডাই অক্সাইড এবং জল থেকে খাবার সংশ্লেষ করতে সূর্যের আলো ব্যবহার করে। এবং কিছু অন্যান্য জীব কার্বন ডাই                  \n",
            "2     আইফেল টাওয়ারটি ফ্রান্সের প্যারিসে অবস্থিত বিশ্বের অন্যতম আইকনিক কাঠামো।         অবস্থিত বিশ্বের অন্যতম আইকনিক কাঠামো।             \n",
            "3     ব্লকচেইন হ'ল একটি বিকেন্দ্রীভূত ডিজিটাল লেজার যা লেনদেনগুলি নিরাপদে এবং স্বচ্ছভাবে রেকর্ড করার জন্য ব্যবহৃত হয়। এবং স্বচ্ছভাবে                                    \n",
            "4     লিওনার্দো দা ভিঞ্চি ছিলেন মোনা লিসা এবং দ্য লাস্ট সাপারের মতো তাঁর কাজের জন্য পরিচিত রেনেসাঁ সময়ের একটি পলিম্যাথ। সাপারের মতো তাঁর কাজের জন্য পরিচিত                \n",
            "5     জলবায়ু পরিবর্তন মূলত মানুষের ক্রিয়াকলাপের কারণে তাপমাত্রা এবং আবহাওয়ার নিদর্শনগুলিতে দীর্ঘমেয়াদী পরিবর্তনকে বোঝায়। এবং আবহাওয়ার নিদর্শনগুলিতে দীর্ঘমেয়াদী          \n",
            "6     অ্যামাজন রেইনফরেস্ট হ'ল বিশ্বের বৃহত্তম গ্রীষ্মমন্ডলীয় রেইন ফরেস্ট, বিভিন্ন উদ্ভিদ এবং প্রাণীজগতের বাড়ি। রেইনফরেস্ট                                        \n",
            "7     পাইথন একটি বহুমুখী প্রোগ্রামিং ভাষা যা একাধিক প্রোগ্রামিং দৃষ্টান্ত সমর্থন করে।  পাইথন একটি বহুমুখী                                \n",
            "8     চাঁদ পৃথিবীর প্রদক্ষিণ করে এবং এর একমাত্র প্রাকৃতিক উপগ্রহ, জোয়ার এবং রাতের সময় আলোকসজ্জা প্রভাবিত করে। করে।                                              \n"
          ]
        }
      ]
    }
  ]
}